---
title: "Vancouver Crime Prediction Report"
author: "Ramiro Francisco Mejia, Jasmine Ortega, Thomas Siu, Shi Yan Wang </br>"
bibliography: references.bib
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(reticulate)
```

## Summary

In this project, we attempt to create a classification prediction model to predict the types of crimes that happens in Vancouver, BC based on neighborhood location and time of the crime. When tested on the unseen test data, the final classifier, LogisticRegression, performed mediocre. Of the 7504 test cases, PLACEHOLDER cases were correctly predicted the optimized model.

## Introduction

Crime is a daily occurrence in large cities, and Vancouver is no exception to this rule. While crime is impossible to avoid in a large metropolitan city, we are interested in seeing if the categories of crimes and timing of crime can be correlated with certain neighborhoods in Vancouver. This project is for educational purposes only and should not be used to predict crime in real life. 

## Methods
The Python programming language [@Python] and the following Python packages were used to perform the analysis: Pandas [@Pandas], Numpy [@Numpy], Sci-Kit Learn [@sklearn], Altair [@altair]


The code used to perform the analysis and create this report can be found here: https://github.com/UBC-MDS/DSCI_522_Crime_Prediction_Vancouver/blob/main/src/modelling.ipynb


## Data
The data was collected by the Vancouver Police Department from 2004 to 2020 and is a log of all crimes committed. Each row in the dataset represents the crime committed, the time of day, neighborhood, the hundreds block the crime occurred on, as well as the X and Y coordinates of the crime location. It is updated weekly by the VPD, but there is about a two to three month lag in logging present day crime. 

## Analysis
The LogisticRegressor algorithm was used to classify the different categories of crimes in Vancouver. It performed best out of the four models tested, which included DummyClassifier (to set a baseline score), RandomForestClassifier, and RidgeClassifier. Scoring was done using f-1, which is the harmonic mean of precision and recall of the classifier. 


```{r model results, echo=FALSE, fig.height = 10, fig.width = 10, fig.cap = "Fig 1. Model Results", out.width = "200%"}

include_graphics('../results/models_results_cv.png')

```
For LogisticRegression, hyperparameters C and class_weight were optimized via RandomizedSearchCV. The best model performed using C = 0.01 and class_weight = None.
From the confusion matrix, we can see that the LogisticRegressor model was able to identify PLACEHOLDER on the test data.

```{r confusion-matrix, echo=FALSE, fig.height = 10, fig.width = 10, fig.cap = "Fig 2. Confusion Matrix of LogisticRegressor performance on test data", out.width = "200%"}

include_graphics('../results/confusion_matrix.png')

```
```{r classification report, echo=FALSE, fig.height = 15, fig.width = 10, fig.cap = "Fig 1. Classification Report of Targets", out.width = "300%"}

include_graphics('../results/classification_report.png')

```

## Results and Discussion
Overall, the model created performs poorly on the test data. This model would not generalize well on unseen data, thus could be improved upon in future updates. 

To further improve the model in the future, we recommend testing different model than LogisticRegressor, RandomForestClassifier, and RidgeClassifier. More importantly, feature engineering could be used to optimize/create new features in the dataset to boost model predictions. Additionally, adding relevant data from an outside source (ie. Vancouver weather, Vancouver unemployment rates, etc.) could be useful to create more meaningful features for the model to train on. 

## References

