{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e91b49-415f-498b-9738-87eb66433305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "alt.data_transformers.enable('data_server')\n",
    "alt.renderers.enable('mimetype')\n",
    "import random\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, RidgeCV, RidgeClassifier\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy.stats import lognorm, loguniform, randint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a9cd4e-3dea-468a-a31a-9dda809f1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/training_feature.csv', index_col=\"index\")\n",
    "y_train = pd.read_csv('../data/processed/training_target.csv', index_col=\"index\").loc[:,\"TYPE\"]\n",
    "\n",
    "X_test = pd.read_csv('../data/processed/test_feature.csv', index_col=\"index\")\n",
    "y_test = pd.read_csv('../data/processed/test_target.csv', index_col=\"index\").loc[:,\"TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2788ca-1f35-460d-9c7d-6ef48ed41b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/processed/preprocessor.p', 'rb')\n",
    "preprocessor = pickle.load(file)\n",
    "\n",
    "file = open('../data/processed/models.p', 'rb')\n",
    "models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b46fb4-61d1-4a9a-998a-2002ef0d3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adopted from lecture notes of DSCI 571 and DSCI 573\n",
    "\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebd26c7-26cf-48de-b6dc-59c794b236c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformation\n",
    "\n",
    "#drop_features = [\"HUNDRED_BLOCK\"]\n",
    "#categorical_feature_n = [\"NEIGHBOURHOOD\"]\n",
    "#categorical_features = [\"YEAR\", \"MONTH\", \"DAY\", \"HOUR\", \"MINUTE\"]\n",
    "#numerical_features = [\"X\", \"Y\"]\n",
    "\n",
    "# preprocessor for EDA and model training\n",
    "#preprocessor = make_column_transformer(\n",
    "\n",
    "#    (make_pipeline(\n",
    "#                SimpleImputer(strategy=\"constant\", fill_value=\"most_frequent\"),\n",
    "#                OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "#            ), categorical_feature_n,\n",
    "#        ),\n",
    "#\n",
    "#    (OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary',\n",
    "#                   sparse=False), categorical_features),\n",
    "#\n",
    "#    (make_pipeline(\n",
    "#               SimpleImputer(strategy=\"most_frequent\"), # these are coordinates\n",
    "#               StandardScaler(),\n",
    "#           ), numerical_features\n",
    "#       ),\n",
    "#        (\"drop\", drop_features),\n",
    "#    )\n",
    "\n",
    "#models = {\n",
    "#    \"DummyClassifier\": DummyClassifier(),\n",
    "#    \"LogisticRegression\": LogisticRegression(max_iter=1000, multi_class=\"ovr\"),\n",
    "#    \"RandomForest\": RandomForestClassifier(),\n",
    "#    \"RidgeClassifier\": RidgeClassifier()\n",
    "#    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4969ddd6-6834-4a3b-a324-79a783f3be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DummyClassifier': DummyClassifier(),\n",
       " 'LogisticRegression': LogisticRegression(max_iter=1000, multi_class='ovr'),\n",
       " 'RandomForest': RandomForestClassifier(),\n",
       " 'RidgeClassifier': RidgeClassifier()}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f643f1f-aa69-4b2f-9013-5ce35b6081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_models(models, X_train, y_train, cv=5):\n",
    "    \"\"\"Returns CV f1 scores\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        A list of sklearn classifiers\n",
    "    X_train : numpy ndarray\n",
    "        The feature matrix\n",
    "    y_train : numpy ndarray\n",
    "        The target labels\n",
    "    cv : int, optional\n",
    "        Number of folds, default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        The results of cross validation for the given models\n",
    "    \"\"\"\n",
    "    f1_scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "    scoring_metrics = {\n",
    "\n",
    "        \"f1\": f1_scorer,\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "\n",
    "        pipe = make_pipeline(preprocessor, model)\n",
    "\n",
    "        results[name] = mean_std_cross_val_scores(\n",
    "            pipe, X_train, y_train, cv=cv, return_train_score=True, scoring=scoring_metrics\n",
    "        )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9775054c-aaec-4ccc-a59c-ef585cc414d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.062 (+/- 0.004)</td>\n",
       "      <td>4.435 (+/- 0.145)</td>\n",
       "      <td>5.515 (+/- 0.087)</td>\n",
       "      <td>0.161 (+/- 0.007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.032 (+/- 0.002)</td>\n",
       "      <td>0.045 (+/- 0.002)</td>\n",
       "      <td>0.203 (+/- 0.000)</td>\n",
       "      <td>0.061 (+/- 0.014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.277 (+/- 0.000)</td>\n",
       "      <td>0.471 (+/- 0.001)</td>\n",
       "      <td>0.463 (+/- 0.003)</td>\n",
       "      <td>0.467 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.277 (+/- 0.000)</td>\n",
       "      <td>0.478 (+/- 0.001)</td>\n",
       "      <td>0.981 (+/- 0.001)</td>\n",
       "      <td>0.474 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DummyClassifier LogisticRegression       RandomForest  \\\n",
       "fit_time    0.062 (+/- 0.004)  4.435 (+/- 0.145)  5.515 (+/- 0.087)   \n",
       "score_time  0.032 (+/- 0.002)  0.045 (+/- 0.002)  0.203 (+/- 0.000)   \n",
       "test_f1     0.277 (+/- 0.000)  0.471 (+/- 0.001)  0.463 (+/- 0.003)   \n",
       "train_f1    0.277 (+/- 0.000)  0.478 (+/- 0.001)  0.981 (+/- 0.001)   \n",
       "\n",
       "              RidgeClassifier  \n",
       "fit_time    0.161 (+/- 0.007)  \n",
       "score_time  0.061 (+/- 0.014)  \n",
       "test_f1     0.467 (+/- 0.001)  \n",
       "train_f1    0.474 (+/- 0.001)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_models(models, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9bb651-39d3-40e5-82f0-098f9f06980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_LR_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Finds the best LR model based on C and weight class, based on f1 scorer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        A list of sklearn classifiers\n",
    "    X_train : numpy ndarray\n",
    "        The feature matrix\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary \n",
    "        dictionary with scores and best hyper parameter\n",
    "    \"\"\"\n",
    "    pipe = make_pipeline(preprocessor,\n",
    "                         LogisticRegression(max_iter=1000,\n",
    "                                         multi_class='ovr',))\n",
    "\n",
    "    f1_scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "    scoring_metrics = {\n",
    "\n",
    "        \"f1\": f1_scorer,\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        \"logisticregression__C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"logisticregression__class_weight\": [None, \"balanced\"]\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_grid,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        n_iter=10,\n",
    "        return_train_score=True,\n",
    "        scoring=make_scorer(f1_score, average='micro'),\n",
    "        random_state=123,\n",
    "    )\n",
    "    search.fit(X_train, y_train);\n",
    "\n",
    "    search_df = pd.DataFrame(search.cv_results_).loc[pd.DataFrame(search.cv_results_)['rank_test_score']==1,[\"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_logisticregression__C\",\n",
    "        \"param_logisticregression__class_weight\"]].T\n",
    "\n",
    "    best_C = search.best_params_['logisticregression__C']\n",
    "    best_weight = search.best_params_['logisticregression__class_weight']\n",
    "\n",
    "    dict = {'scores': search_df,\n",
    "            'best_C': best_C,\n",
    "            'best_weight': best_weight}\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce661b1-12c0-4acd-892a-59faa93b842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "best_LR_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112f33f-6c28-465d-adba-732131880017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(pipe):\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    print(classification_report(y_test, pipe.predict(X_test), target_names=pipe.classes_));\n",
    "\n",
    "    y_preb_probs = pipe_best.predict_proba(X_test)\n",
    "    print(f\"MODEL'S ROC AUC SCORE IS :{round(roc_auc_score(y_test, y_preb_probs, average='weighted', multi_class='ovr'), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec245c-03d4-4929-b6cd-467fe421a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_best = make_pipeline(preprocessor,\n",
    "                         LogisticRegression(max_iter=1000,\n",
    "                                            multi_class='ovr',\n",
    "                                            C=0.1))\n",
    "print_scores(pipe_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68177677-32f4-4830-be1e-efd18279f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(pipe):\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    cm = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe, X_test, y_test, values_format=\"d\", display_labels=pipe.classes_\n",
    "    ).figure_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e39536-7a63-4799-9fde-5d860364a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(pipe_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crime_predictor]",
   "language": "python",
   "name": "conda-env-.conda-crime_predictor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
